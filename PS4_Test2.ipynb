{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Venettov/Riveraruiz_GIS/blob/main/PS4_Test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O485bWoQ_Fk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "78fc2857-e1df-48d5-d7c6-7d90a9e0ab26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopandas==1.0.1 in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from geopandas==1.0.1) (1.26.4)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas==1.0.1) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas==1.0.1) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from geopandas==1.0.1) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas==1.0.1) (3.7.0)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas==1.0.1) (2.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas==1.0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas==1.0.1) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas==1.0.1) (2024.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyogrio>=0.7.2->geopandas==1.0.1) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas==1.0.1) (1.16.0)\n",
            "Collecting mapclassify\n",
            "  Downloading mapclassify-2.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.10/dist-packages (from mapclassify) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from mapclassify) (1.26.4)\n",
            "Requirement already satisfied: pandas!=1.5.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from mapclassify) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from mapclassify) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from mapclassify) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.5.0,>=1.4->mapclassify) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.5.0,>=1.4->mapclassify) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.5.0,>=1.4->mapclassify) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->mapclassify) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->mapclassify) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas!=1.5.0,>=1.4->mapclassify) (1.16.0)\n",
            "Downloading mapclassify-2.8.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mapclassify\n",
            "Successfully installed mapclassify-2.8.1\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: folium in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.26.4)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.7.0)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.6)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from folium) (0.8.0)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from folium) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from folium) (2.32.3)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.10/dist-packages (from folium) (2024.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9->folium) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (2.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.26.4)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.7.0)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.6)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh) (1.3.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh) (2024.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.26.4)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.7.0)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.6)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
            "Collecting hvplot\n",
            "  Downloading hvplot-0.11.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: bokeh>=3.1 in /usr/local/lib/python3.10/dist-packages (from hvplot) (3.6.1)\n",
            "Requirement already satisfied: colorcet>=2 in /usr/local/lib/python3.10/dist-packages (from hvplot) (3.1.0)\n",
            "Requirement already satisfied: holoviews>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from hvplot) (1.20.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from hvplot) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hvplot) (24.2)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from hvplot) (2.2.2)\n",
            "Requirement already satisfied: panel>=1.0 in /usr/local/lib/python3.10/dist-packages (from hvplot) (1.5.4)\n",
            "Requirement already satisfied: param<3.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from hvplot) (2.1.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->hvplot) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->hvplot) (1.3.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->hvplot) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->hvplot) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->hvplot) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->hvplot) (2024.9.0)\n",
            "Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.10/dist-packages (from holoviews>=1.19.0->hvplot) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->hvplot) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->hvplot) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->hvplot) (2024.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->hvplot) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->hvplot) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->hvplot) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->hvplot) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->hvplot) (0.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->hvplot) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->hvplot) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->hvplot) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh>=3.1->hvplot) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3->hvplot) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.0->hvplot) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.0->hvplot) (1.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.0->hvplot) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=1.0->hvplot) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=1.0->hvplot) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=1.0->hvplot) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=1.0->hvplot) (2024.8.30)\n",
            "Downloading hvplot-0.11.1-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hvplot\n",
            "Successfully installed hvplot-0.11.1\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.0\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (2.0.6)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely) (1.26.4)\n",
            "Collecting dash\n",
            "  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash) (3.0.3)\n",
            "Collecting Werkzeug<3.1 (from dash)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (5.24.1)\n",
            "Collecting dash-html-components==2.0.0 (from dash)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting dash-table==5.0.0 (from dash)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash) (2.32.3)\n",
            "Collecting retrying (from dash)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash) (75.1.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (1.9.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash) (24.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<3.1->dash) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dash) (1.16.0)\n",
            "Downloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Downloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install geopandas==1.0.1\n",
        "!pip install mapclassify\n",
        "!pip install geopandas folium\n",
        "!pip install requests\n",
        "!pip install geopandas bokeh\n",
        "!pip install geopandas plotly\n",
        "!pip install hvplot\n",
        "!pip install xlsxwriter\n",
        "!pip install shapely\n",
        "!pip install dash\n",
        "!pip install bokeh\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TITLE**\n",
        "\n",
        "### *Exploring Population Rates, Employment, and Demographic Data: A GIS Project in Puerto Rico*\n",
        "\n",
        "\n",
        "#**DESCRIPTION**\n",
        "\n",
        "### *The primary objective of this project is to analyze and compare population and employment rates across the various towns of Puerto Rico*\n",
        "\n",
        "#**DATASET SOURCES**\n",
        "\n",
        "### Population Density Data:\n",
        "\n",
        "#### https://censo.estadisticas.pr/EstimadosPoblacionales\n",
        "\n",
        "## Employment Data:\n",
        "\n",
        "#### https://indicadores.pr/dataset/tasa-desempleo-municipio-area/resource/8de254b0-b769-4a4e-b145-9a6975369b91\n",
        "\n",
        "## Demographic Data:\n",
        "\n",
        "#### https://censo.estadisticas.pr/node/520\n",
        "\n",
        "Puerto Rico has faced natural disasters, corruption, mismanagement by local government, and mass emigration that has resulted in a critical loss of professionals and has essentially reduced the island’s student population to levels I never imagined. I myself emigrated after finishing college in search of better job opportunities.\n",
        "\n",
        "As indicated by the State Data Center of Puerto Rico’s website (https://censo.estadisticas.pr/), the population has been declining for decades and the pace has accelerated in recent years. The exodus, which includes a large portion of young people, has accelerated the aging of the population. I have even noticed this personally when I visit the island; my village is mostly occupied by people over 50 years old. As a direct consequence, the birth rate is also low. The government has also closed many schools due to the drop in student numbers and as an austerity measure in the face of the economic crisis.\n",
        "\n",
        "To counteract the loss of population, Puerto Rico must adopt measures that shore up its economy, security, education and expand employment opportunities. Population data analysis presentation can be used to support tax reforms and enhance the island’s attractions. Data and its proper use can help to have a better Puerto Rico.\n",
        "\n",
        "## Financial and fiscal information of Puerto Rico:\n",
        "\n",
        "#### https://www.observatoriofiscalpr.com/\n",
        "The Fiscal Observatory is a tool that democratizes the financial and fiscal information of Puerto Rico, making it accessible to both the expert and the general public. Data is based on official information from the government of Puerto Rico. The platform includes comments and publications from analysts and experts on budget, debt, municipalities and recovery.\n",
        "\n"
      ],
      "metadata": {
        "id": "hCokap_GPMuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Housing information of Puerto Rico:\n",
        "\n",
        "Housing Information fro Puerto Rico was oobtained from : https://datos.opal.pr.gov/datos-socioeconomicos/municipios/vivienda?filter=72153\n",
        "\n",
        "\n",
        "\n",
        "Puerto Rico's housing crisis is characterized by a shortage of affordable housing, high property prices, and a decline in population:\n",
        "\n",
        "Affordable housing\n",
        "\n",
        "The median household incomes have only increased by 24%. More than 300,000 households spend more than 30% of their income on housing, which is above the HUD-recommended maximum.\n",
        "\n",
        "Property prices\n",
        "The average price of properties for sale in Puerto Rico increased by 63% between 2012 and 2023.\n",
        "\n",
        "Some of the causes of Puerto Rico's housing crisis include:\n",
        "*Economic challenges\n",
        "Puerto Rico has been dealing with economic difficulties for years, including a debt crisis and high unemployment.\n",
        "\n",
        "*Construction challenges\n",
        "The cost of construction materials is high, and there are labor shortages.\n",
        "\n",
        "\n",
        "## Earthquakes information for Puerto Rico:\n",
        "\n",
        "The 2020 Puerto Rico earthquakes caused significant damage to many structures in the southwestern region of the island, including buildings, roadways, and bridges:\n",
        "\n",
        "•\tHomes: Over 8,000 homes were damaged, with about 2,500 uninhabitable.\n",
        "\n",
        "•\tSchools: The Escuela Intermedia Agripina Seda middle school in Guanica\n",
        "suffered major damage, including a partially collapsed, three-story building.\n",
        "\n",
        "•\tChurches: The Guyanilla Catholic Church in downtown Guyanilla was partially collapsed.\n",
        "\n",
        "•\tGovernment structures: Damage to government structures was calculated in the hundreds of millions.\n",
        "\n",
        "•\tOther structures: At least 80 structures collapsed completely.\n",
        "\n",
        "The earthquakes occurred in a series of events, starting on December 28, 2019 and continuing through January 2020. The first major event was a magnitude 5.8 earthquake on January 6, followed by a magnitude 6.4 earthquake on January 7, and a magnitude 5.6 earthquake on January 7. The region continued to experience aftershocks for years to decades.\n",
        "\n",
        "This article summarizes the events and presents many photos of damagedstructures in the southwest of the island: https://www.usatoday.com/picture-gallery/news/nation/2020/01/07/puerto-rico-earthquakes-cause-heavy-damage-and-knock-out-power/2830812001/\n",
        "\n",
        "This is the source for the earthquakes data: https://earthquake.usgs.gov/earthquakes/search/\n",
        "* I filtered my search for the years 2020 to 2024 and over the entire geographical area of Puerto Rico\n"
      ],
      "metadata": {
        "id": "NBcEbHPJKsEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile #basics\n",
        "import pandas as pd #data management\n",
        "import matplotlib.pyplot as plt #visualization library\n",
        "import geopandas as gpd #gis/maps library\n",
        "\n",
        "import mapclassify\n",
        "import requests\n",
        "\n",
        "#will display all output not just last command\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from google.colab import files #to download from colab onto hd\n",
        "\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter() #this enables spreadsheet view upon calling dataframe\n",
        "\n",
        "from decimal import Decimal, ROUND_HALF_UP\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wamKXAedAGQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The shapefile informatition was downloaded from: https://data.humdata.org/dataset/cod-ab-pri?\n",
        "# I could donwload the zile file directly from the source and get the same result (line below)\n",
        "#! wget -q -O pr-counties.zip https://data.humdata.org/dataset/e71a08a7-8529-4964-9ad7-7319e6ec05f8/resource/d3b8f932-16cf-4ecb-89b8-c2611922fcb4/download/pri_adm_2019_shp.zip\n",
        "\n",
        "# I saved the file on Google Drive and created the link below:\n",
        "\n",
        "! wget -q -O pr-counties.zip https://drive.google.com/uc?id=14I-sv4Q-3oCtdNXerqPGJZ9QkG37b48C&export=download\n",
        "\n",
        "zip_ref = zipfile.ZipFile('pr-counties.zip', 'r'); zip_ref.extractall(); zip_ref.close() #just unzipping\n",
        "prC0=gpd.read_file('original/pri_admbnda_adm1_2019.shp') #load the shapefile with gpd as prC\n",
        "prC1=gpd.read_file('original/pri_admbndl_ALL_2019.shp') #load the shapefile with gpd as prC\n",
        "\n"
      ],
      "metadata": {
        "id": "zamlLuBcBSQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "     #The file below is Población_total_en_Municipios_2020-2023.csv\n",
        "#This file was downloaded from: https://censo.estadisticas.pr/EstimadosPoblacionales\n",
        "! wget -q -O population.csv https://drive.google.com/uc?id=1PNPIPJO03Qv97wvvpGgkf018pp3ORp_9&export=download\n",
        "#df_pop = pd.read_csv(\"population.csv\")\n",
        "\n",
        "# Read the Excel file\n",
        "df = pd.read_excel(\"https://docs.google.com/uc?id=1BUHN_8oYFdiOVKBTQKxXZYD2HHmYnZXq&export=download\")\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(\"output.csv\", index=False)\n",
        "\n",
        "# Read the CSV file with float values\n",
        "df_population = pd.read_csv(\"output.csv\", dtype={'2023': float})\n",
        "\n",
        "#df_population.dtypes\n",
        "\n",
        "#The file below is pr_unemployment_rates.csv\n",
        "#This file was downloaded from: https://indicadores.pr/dataset/tasa-desempleo-municipio-area/resource/8de254b0-b769-4a4e-b145-9a6975369b91\n",
        "! wget -q -O unem.csv https://drive.google.com/uc?id=1Ix9WCtGqJAHmptO6BdbD826lvKhKpPzE&export=download\n",
        "#df_unemployment = pd.read_csv(\"unem.csv\")\n",
        "\n",
        "\n",
        "# Read the Excel file\n",
        "df_unemp = pd.read_excel(\"https://docs.google.com/uc?id=1Okd--IC4hkcBnCfG02yl5_7yHiCTUgIw&export=download\")\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_unemp.to_csv(\"output.csv\", index=False)\n",
        "\n",
        "# Read the CSV file with float values\n",
        "df_unemployment = pd.read_csv(\"output.csv\")\n",
        "#df_unemployment.dtypes\n",
        "\n",
        "\n",
        "#The file below is datos_municipales.csv\n",
        "#This file was downloaded from: https://censo.estadisticas.pr/node/520\n",
        "! wget -q -O gen.csv https://drive.google.com/uc?id=18Au9nBwdMdG6GJqR5jz3qly8Yf3IzfuJ&export=download\n",
        "#df_gen = pd.read_csv(\"gen.csv\")\n",
        "\n",
        "# Read the Excel file\n",
        "df_g = pd.read_excel(\"https://docs.google.com/uc?id=1QNzLPNfzSVKfUJiqZiDWaeobk6RzMtVs&export=download\")\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_g.to_csv(\"output.csv\", index=False)\n",
        "\n",
        "# Read the CSV file with float values\n",
        "df_gen = pd.read_csv(\"output.csv\")\n",
        "#df_gen.dtypes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P2bZNzx6JdLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Some towns include special characters that gagve me some trouble when merging the Shapefile wkth the CSV files.\n",
        "# I created the structure below to include all those towns and create a new Shapefile qith the name of towns without special characters\n",
        "\n",
        "# Define the words to search for and their replacements\n",
        "replacements = {\n",
        "    'Mayagüez': 'Mayaguez',\n",
        "    'Canóvanas': 'Canovanas',\n",
        "    'Comerío': 'Comerio',\n",
        "    'Manatí': 'Manati',\n",
        "    'San Sebastián': 'San Sebastian',\n",
        "    'San Germán': 'San German',\n",
        "    'Rincón': 'Rincon',\n",
        "    'Juana Díaz': 'Juana Diaz',\n",
        "    'Loíza': 'Loiza',\n",
        "    'Bayamón': 'Bayamon',\n",
        "    'Río Grande': 'Rio Grande',\n",
        "    'Las Marías': 'Las Marias',\n",
        "    'Guánica': 'Guanica'\n",
        "}\n",
        "\n",
        "# Replace the words in the specified column (e.g., 'name' column)\n",
        "for old_word, new_word in replacements.items():\n",
        "    prC0['ADM1_ES'] = prC0['ADM1_ES'].str.replace(old_word, new_word)\n",
        "\n",
        "# Save the modified shapefile\n",
        "prC0.to_file('merged_shapefile.shp')\n",
        "prC0=gpd.read_file('merged_shapefile.shp')\n",
        "\n"
      ],
      "metadata": {
        "id": "Yb6PadPIPLzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reviewing what information is available in the CSV documents"
      ],
      "metadata": {
        "id": "dnHgi2PEA1f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#aok slow down with merging, explore the result eg\n",
        "df_pop_unem = pd.merge(df_population, df_unemployment, on='Municipio',how='outer',indicator='_merge')\n",
        "#df_pop_unem[['Municipio','_merge']]"
      ],
      "metadata": {
        "id": "zV4BsLfF8JMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pop_unem = pd.merge(df_population, df_unemployment, on='Municipio',how='inner')\n",
        "\n",
        "# Below I'm merging the general populatiton, unemployment data, and genal populatiton data using the town's name\n",
        "df_pop_unem_gen = pd.merge(df_pop_unem, df_gen, on='Municipio')\n",
        "#df_pop_unem_gen.head(78)\n",
        "\n",
        "# Merge the shapefile with all the data on different column names using the town's name\n",
        "merged_data = prC0.merge(df_pop_unem_gen, left_on='ADM1_ES', right_on='Municipio',how='outer',indicator='_merge')\n",
        "\n",
        "#merged_data[['ADM1_ES','Municipio','_merge']]"
      ],
      "metadata": {
        "id": "imEuLicB8_RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below I'm exploring the data contained inside the csv file with populatition data.\n",
        "#df_population.columns\n",
        "#df_unemployment.columns\n",
        "#df_gen.columns\n",
        "\n",
        "# Below I'm merging the general populatiton and the unemployment data using the town's name\n",
        "df_pop_unem = pd.merge(df_population, df_unemployment, on='Municipio')\n",
        "#df_pop_unem.head(78)\n",
        "\n",
        "# Below I'm merging the general populatiton, unemployment data, and genal populatiton data using the town's name\n",
        "df_pop_unem_gen = pd.merge(df_pop_unem, df_gen, on='Municipio')\n",
        "#df_pop_unem_gen.head(78)\n",
        "\n",
        "# Merge the shapefile with all the data on different column names using the town's name\n",
        "merged_data = prC0.merge(df_pop_unem_gen, left_on='ADM1_ES', right_on='Municipio')\n",
        "\n",
        "# Printing the merged data to verify everything is there!\n",
        "merged_data.columns = merged_data.columns.str.replace(' ', '_')\n",
        "#merged_data\n",
        "\n",
        "# Save the merged_data DataFrame to a CSV file with the specified name\n",
        "merged_data.to_csv('merged_data_general_information.csv', index=False)\n",
        "\n",
        "# Display the updated column names to verify\n",
        "#print(merged_data.columns)\n",
        "\n"
      ],
      "metadata": {
        "id": "G1KJqUodAq_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The file below is gastos_de_municipios.xlsx\n",
        "#This file was downloaded from: https://www.observatoriofiscalpr.com/\n",
        "df_spend = pd.read_excel(\"https://docs.google.com/uc?id=1vGW_nb6zrRDwOJD1FYtWNTalTaZXigJC&export=download\")\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_spend.to_csv(\"spend.csv\", index=False)\n",
        "\n",
        "# Read the CSV file with float values\n",
        "df_spendings = pd.read_csv(\"spend.csv\")\n",
        "#df_spendings.dtypes\n",
        "\n",
        "#The file below is ingresos_de_municipios.xlsx\n",
        "#This file was downloaded from: https://www.observatoriofiscalpr.com/\n",
        "# Read the Excel file\n",
        "df_income = pd.read_excel(\"https://docs.google.com/uc?id=1QZTTT75eSuesSEDKT5HwKf1EEAKgRoE_&export=download\")\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_income.to_csv(\"incomes.csv\", index=False)\n",
        "\n",
        "# Read the CSV file with float values\n",
        "df_incomes = pd.read_csv(\"incomes.csv\")\n",
        "#df_incomes.dtypes\n",
        "\n",
        "\n",
        "#The file below is deuda-publica-de-municipi.xlsx\n",
        "#This file was downloaded from: https://www.observatoriofiscalpr.com/\n",
        "# Read the Excel file\n",
        "df_debt = pd.read_excel(\"https://docs.google.com/uc?id=1vXF8gRDR0sO95TmAMm42gJ1XLgekBGWV&export=download\")\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_debt.to_csv(\"debts.csv\", index=False)\n",
        "\n",
        "# Read the CSV file with float values\n",
        "df_debts = pd.read_csv(\"debts.csv\")\n",
        "#df_debts.dtypes"
      ],
      "metadata": {
        "id": "0t6MyN2WLSv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to remove the specified phrase from each column name\n",
        "def clean_column_name(column_name):\n",
        "    return column_name.replace(\"Todos los tipos - \", \"\")\n",
        "\n",
        "# Update the column names\n",
        "df_debts.columns = [clean_column_name(col) for col in df_debts.columns]\n",
        "df_spendings.columns = [clean_column_name(col) for col in df_debts.columns]\n",
        "df_incomes.columns = [clean_column_name(col) for col in df_debts.columns]\n",
        "\n",
        "# Save the modified DataFrame back to a CSV (if needed)\n",
        "df_debts.to_csv('debts.csv', index=False)\n",
        "df_spendings.to_csv('spendings.csv', index=False)\n",
        "df_incomes.to_csv('incomes.csv', index=False)"
      ],
      "metadata": {
        "id": "t6cOGCT8eBGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Your replacements dictionary\n",
        "replacements = {\n",
        "    'Mayagüez': 'Mayaguez',\n",
        "    'Canóvanas': 'Canovanas',\n",
        "    'Comerío': 'Comerio',\n",
        "    'Manatí': 'Manati',\n",
        "    'San Sebastián': 'San Sebastian',\n",
        "    'San Germán': 'San German',\n",
        "    'Rincón': 'Rincon',\n",
        "    'Juana Díaz': 'Juana Diaz',\n",
        "    'Loíza': 'Loiza',\n",
        "    'Bayamón': 'Bayamon',\n",
        "    'Río Grande': 'Rio Grande',\n",
        "    'Las Marías': 'Las Marias',\n",
        "    'Guánica': 'Guanica'\n",
        "}\n",
        "\n",
        "\n",
        "# Function to replace words in the column name based on replacements dictionary\n",
        "def replace_words(column_name, replacements):\n",
        "    for old_word, new_word in replacements.items():\n",
        "        if old_word in column_name:\n",
        "            column_name = column_name.replace(old_word, new_word)\n",
        "    return column_name\n",
        "\n",
        "# Update the column names\n",
        "df_debts.columns = [replace_words(col, replacements) for col in df_debts.columns]\n",
        "df_spendings.columns = [replace_words(col, replacements) for col in df_spendings.columns]\n",
        "df_incomes.columns = [replace_words(col, replacements) for col in df_incomes.columns]\n",
        "\n",
        "# Create the \"Puerto Rico\" column by summing each row excluding the first column (Year)\n",
        "df_debts['Puerto Rico'] = df_debts.iloc[:, 1:].sum(axis=1)\n",
        "df_spendings['Puerto Rico'] = df_spendings.iloc[:, 1:].sum(axis=1)\n",
        "df_incomes['Puerto Rico'] = df_incomes.iloc[:, 1:].sum(axis=1)\n",
        "\n",
        "# Save the modified DataFrame back to a CSV (if needed)\n",
        "#df_incomes.to_csv('modified_file.csv', index=False)\n",
        "df_debts.to_csv('debts.csv', index=False)\n",
        "df_spendings.to_csv('spendings.csv', index=False)\n",
        "df_incomes.to_csv('incomes.csv', index=False)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "#df_incomes.head()\n",
        "#df_spendings.head()\n",
        "#df_debts.head()\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "v41Sq131kzsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the incomes DataFrame\n",
        "df_debts.to_csv('debts.csv', index=False)\n",
        "df_spendings.to_csv('spendings.csv', index=False)\n",
        "df_incomes = pd.read_csv('incomes.csv')\n",
        "\n",
        "# Replace 'Período fiscal' with 'Municipio'\n",
        "df_incomes.rename(columns={'Período fiscal': 'Municipio'}, inplace=True)\n",
        "df_debts.rename(columns={'Período fiscal': 'Municipio'}, inplace=True)\n",
        "df_spendings.rename(columns={'Período fiscal': 'Municipio'}, inplace=True)\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "df_incomes.to_csv('updated_incomes.csv', index=False)\n",
        "df_debts.to_csv('updated_debts.csv', index=False)\n",
        "df_spendings.to_csv('updated_spendings.csv', index=False)\n",
        "\n",
        "# Transpose the DataFrame\n",
        "df_transposed_incomes = df_incomes.transpose()\n",
        "df_transposed_debts = df_debts.transpose()\n",
        "df_transposed_spendings = df_spendings.transpose()\n",
        "\n",
        "# Save the transposed DataFrame to a new CSV file\n",
        "df_transposed_incomes.to_csv('transposed_incomes.csv', index=True, header=False)\n",
        "df_transposed_debts.to_csv('transposed_debts.csv', index=True, header=False)\n",
        "df_transposed_spendings.to_csv('transposed_spendings.csv', index=True, header=False)\n"
      ],
      "metadata": {
        "id": "7mGCB4-INv-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the transposed incomes DataFrame\n",
        "df_transposed_incomes = pd.read_csv('transposed_incomes.csv')\n",
        "df_transposed_debts = pd.read_csv('transposed_debts.csv')\n",
        "df_transposed_spendings = pd.read_csv('transposed_spendings.csv')\n",
        "\n",
        "# Scale down the float values to avoid exceeding field width\n",
        "# We will multiply by a scaling factor to ensure the values fit\n",
        "scaling_factor = 1e-6  # Adjust this factor as needed\n",
        "float_columns = df_transposed_incomes.select_dtypes(include=['float64']).columns\n",
        "df_transposed_incomes[float_columns] = df_transposed_incomes[float_columns].apply(lambda x: x * scaling_factor)\n",
        "\n",
        "float_columns_debt = df_transposed_debts.select_dtypes(include=['float64']).columns\n",
        "df_transposed_debts[float_columns] = df_transposed_debts[float_columns].apply(lambda x: x * scaling_factor)\n",
        "\n",
        "float_columns_spendings = df_transposed_spendings.select_dtypes(include=['float64']).columns\n",
        "df_transposed_spendings[float_columns] = df_transposed_spendings[float_columns].apply(lambda x: x * scaling_factor)\n",
        "\n",
        "# Load the shapefile into a GeoDataFrame\n",
        "prC2 = gpd.read_file('merged_shapefile.shp')\n",
        "\n",
        "# Ensure the 'geometry' column remains intact\n",
        "prC2 = prC2.set_geometry('geometry')\n",
        "\n",
        "# Check if column names match\n",
        "#print(\"df_transposed columns: \", df_transposed_incomes.columns)\n",
        "#print(\"prC2 columns: \", prC2.columns)\n",
        "\n",
        "# Perform the merge\n",
        "try:\n",
        "    merged_df = pd.merge(prC2, df_transposed_incomes, left_on='ADM1_ES', right_on='Municipio')\n",
        "    merged_df_debt = pd.merge(prC2, df_transposed_debts, left_on='ADM1_ES', right_on='Municipio')\n",
        "    merged_df_spendings = pd.merge(prC2, df_transposed_spendings, left_on='ADM1_ES', right_on='Municipio')\n",
        "    print(\"Merge successful!\")\n",
        "\n",
        "    # Ensure the geometry column remains a GeoSeries\n",
        "    merged_df = gpd.GeoDataFrame(merged_df, geometry='geometry')\n",
        "    merged_df_debt = gpd.GeoDataFrame(merged_df_debt, geometry='geometry')\n",
        "    merged_df_spendings = gpd.GeoDataFrame(merged_df_spendings, geometry='geometry')\n",
        "\n",
        "    # Save the merged DataFrame to a new shapefile\n",
        "    merged_df.to_file('merged_with_incomes.shp')\n",
        "    merged_df_debt.to_file('merged_with_debts.shp')\n",
        "    merged_df_spendings.to_file('merged_with_spendings.shp')\n",
        "    print(\"File saved successfully!\")\n",
        "\n",
        "    # Display the merged DataFrame\n",
        "    #print(merged_df.head())\n",
        "    #print(merged_df_debt.head())\n",
        "    #print(merged_df_spendings.head())\n",
        "except Exception as e:\n",
        "    print(\"Error during merge: \", e)\n",
        "\n",
        "# Load the merged shapefile into a GeoDataFrame\n",
        "merged_df = gpd.read_file('merged_with_incomes.shp')\n",
        "merged_df_debt = gpd.read_file('merged_with_debts.shp')\n",
        "merged_df_spendings = gpd.read_file('merged_with_spendings.shp')\n",
        "\n",
        "# Ensure the 'geometry' column remains intact\n",
        "#merged_df.dtypes\n",
        "#merged_df_debt.dtypes\n",
        "#merged_df_spendings.dtypes\n",
        "\n",
        "# Save the GeoDataFrame to a CSV file\n",
        "merged_df.to_csv('merged_with_incomes.csv', index=False)\n",
        "merged_df_debt.to_csv('merged_with_debts.csv', index=False)\n",
        "merged_df_spendings.to_csv('merged_with_spendings.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "tFRO3dymVd-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "merged_data_debt = pd.read_csv('merged_with_debts.csv')\n",
        "merged_data_debt['Difference_2023_2024'] = (merged_data_debt['2024.0'].astype(float) - merged_data_debt['2023.0'].astype(float))*1000000\n",
        "# Create a new column 'Difference_Symbol' for hover tooltips\n",
        "merged_data_debt['Difference_Symbol'] = merged_data_debt['Difference_2023_2024'].apply(lambda x: '↑' if x > 0 else '↓')\n",
        "merged_data_debt['2024_Status'] = merged_data_debt['Difference_2023_2024'].apply(lambda x: 'Debt increased in 2024' if x > 0 else 'Debt decreased in 2024')\n",
        "#merged_data_debt\n",
        "merged_data_debt.to_csv('merged_with_debts.csv', index=False)\n",
        "\n",
        "merged_data_incomes = pd.read_csv('merged_with_incomes.csv')\n",
        "merged_data_incomes['Difference_2023_2024'] = (merged_data_incomes['2024.0'].astype(float) - merged_data_incomes['2023.0'].astype(float))*1000000\n",
        "# Create a new column 'Difference_Symbol' for hover tooltips\n",
        "merged_data_incomes['Difference_Symbol'] = merged_data_incomes['Difference_2023_2024'].apply(lambda x: '↑' if x > 0 else '↓')\n",
        "merged_data_incomes['2024_Status'] = merged_data_incomes['Difference_2023_2024'].apply(lambda x: 'Incomes increased in 2024' if x > 0 else 'Incomes decreased in 2024')\n",
        "#merged_data_incomes\n",
        "merged_data_incomes.to_csv('merged_with_incomes.csv', index=False)\n",
        "\n",
        "merged_data_spendings = pd.read_csv('merged_with_spendings.csv')\n",
        "merged_data_spendings['Difference_2023_2024'] = (merged_data_spendings['2024.0'].astype(float) - merged_data_spendings['2023.0'].astype(float))*1000000\n",
        "# Create a new column 'Difference_Symbol' for hover tooltips\n",
        "merged_data_spendings['Difference_Symbol'] = merged_data_spendings['Difference_2023_2024'].apply(lambda x: '↑' if x > 0 else '↓')\n",
        "merged_data_spendings['2024_Status'] = merged_data_spendings['Difference_2023_2024'].apply(lambda x: 'Spendings increased in 2024' if x > 0 else 'Spendings decreased in 2024')\n",
        "#merged_data_spendings\n",
        "merged_data_spendings.to_csv('merged_with_spendings.csv', index=False)"
      ],
      "metadata": {
        "id": "mw1R5iCnctkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely import wkt\n",
        "from bokeh.io import output_notebook, show\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.models import HoverTool, GeoJSONDataSource, LinearColorMapper, ColorBar\n",
        "from bokeh.palettes import RdYlGn11\n",
        "import json\n",
        "\n",
        "# Enable Bokeh to display plots in the notebook\n",
        "output_notebook()\n",
        "\n",
        "# Load the merged data\n",
        "merged_with_incomes = pd.read_csv('merged_with_incomes.csv')\n",
        "merged_data_debt = pd.read_csv('merged_with_debts.csv')\n",
        "merged_data_spendings = pd.read_csv('merged_with_spendings.csv')\n",
        "\n",
        "# Convert the DataFrame to a GeoDataFrame\n",
        "merged_with_incomes['geometry'] = merged_with_incomes['geometry'].apply(wkt.loads)\n",
        "merged_data_debt['geometry'] = merged_data_debt['geometry'].apply(wkt.loads)\n",
        "merged_data_spendings['geometry'] = merged_data_spendings['geometry'].apply(wkt.loads)\n",
        "gdf = gpd.GeoDataFrame(merged_with_incomes, geometry='geometry')\n",
        "gdf_debt = gpd.GeoDataFrame(merged_data_debt, geometry='geometry')\n",
        "gdf_spendings = gpd.GeoDataFrame(merged_data_spendings, geometry='geometry')\n",
        "\n",
        "# Ensure the CRS is set correctly\n",
        "gdf.set_crs(epsg=4326, inplace=True)\n",
        "gdf_debt.set_crs(epsg=4326, inplace=True)\n",
        "gdf_spendings.set_crs(epsg=4326, inplace=True)\n",
        "\n",
        "# Convert GeoDataFrame to GeoJSON\n",
        "gdf_json = json.loads(gdf.to_json())\n",
        "gdf_json_debt = json.loads(gdf_debt.to_json())\n",
        "gdf_json_spendings = json.loads(gdf_spendings.to_json())\n",
        "\n",
        "# Create a GeoJSONDataSource\n",
        "geo_source = GeoJSONDataSource(geojson=json.dumps(gdf_json))\n",
        "geo_source_debt = GeoJSONDataSource(geojson=json.dumps(gdf_json_debt))\n",
        "geo_source_spendings = GeoJSONDataSource(geojson=json.dumps(gdf_json_spendings))\n",
        "\n",
        "# Define a linear color mapper for debt values (using RdYlGn11 palette)\n",
        "debt_values = gdf_debt['2024.0']\n",
        "color_mapper_debt = LinearColorMapper(palette=RdYlGn11, low=debt_values.min(), high=debt_values.max())\n",
        "\n",
        "# Create a figure for debt\n",
        "p_debt = figure(title=\"Debt for Administrative Towns in Puerto Rico         ~$37 Billions in 2023\",\n",
        "           height=350, width=1100,\n",
        "           tools=\"pan,wheel_zoom,box_zoom,reset,hover,save\",\n",
        "           tooltips=[(\"Town\", \"@ADM1_ES\"), (\"Debt\", \"@Difference_2023_2024\")])\n",
        "\n",
        "# Center the title\n",
        "p_debt.title.align = 'center'\n",
        "\n",
        "# Add patches for the geometries\n",
        "p_debt.patches('xs', 'ys', source=geo_source_debt,\n",
        "          fill_color={'field': 'Difference_2023_2024', 'transform': color_mapper_debt},\n",
        "          line_color=\"black\", line_width=0.25, fill_alpha=0.7)\n",
        "\n",
        "# Add a color bar\n",
        "color_bar_debt = ColorBar(color_mapper=color_mapper_debt, location=(0, 0), orientation=\"horizontal\", title=\"Debt Value\")\n",
        "\n",
        "# Adjust the plot layout\n",
        "p_debt.add_layout(color_bar_debt, 'below')\n",
        "\n",
        "# Show the plot\n",
        "output_notebook()\n",
        "show(p_debt)\n"
      ],
      "metadata": {
        "id": "h1sASkhxTr0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely import wkt\n",
        "from bokeh.io import output_notebook, show\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.models import HoverTool, GeoJSONDataSource, LinearColorMapper, ColorBar\n",
        "from bokeh.palettes import RdYlGn11\n",
        "import json\n",
        "\n",
        "# Enable Bokeh to display plots in the notebook\n",
        "output_notebook()\n",
        "\n",
        "# Load the merged data\n",
        "merged_with_incomes = pd.read_csv('merged_with_incomes.csv')\n",
        "merged_data_debt = pd.read_csv('merged_with_debts.csv')\n",
        "merged_data_spendings = pd.read_csv('merged_with_spendings.csv')\n",
        "\n",
        "# Convert the DataFrame to a GeoDataFrame\n",
        "merged_with_incomes['geometry'] = merged_with_incomes['geometry'].apply(wkt.loads)\n",
        "merged_data_debt['geometry'] = merged_data_debt['geometry'].apply(wkt.loads)\n",
        "merged_data_spendings['geometry'] = merged_data_spendings['geometry'].apply(wkt.loads)\n",
        "gdf = gpd.GeoDataFrame(merged_with_incomes, geometry='geometry')\n",
        "gdf_debt = gpd.GeoDataFrame(merged_data_debt, geometry='geometry')\n",
        "gdf_spendings = gpd.GeoDataFrame(merged_data_spendings, geometry='geometry')\n",
        "\n",
        "# Ensure the CRS is set correctly\n",
        "gdf.set_crs(epsg=4326, inplace=True)\n",
        "gdf_debt.set_crs(epsg=4326, inplace=True)\n",
        "gdf_spendings.set_crs(epsg=4326, inplace=True)\n",
        "\n",
        "# Convert GeoDataFrame to GeoJSON\n",
        "gdf_json = json.loads(gdf.to_json())\n",
        "gdf_json_debt = json.loads(gdf_debt.to_json())\n",
        "gdf_json_spendings = json.loads(gdf_spendings.to_json())\n",
        "\n",
        "# Create a GeoJSONDataSource\n",
        "geo_source = GeoJSONDataSource(geojson=json.dumps(gdf_json))\n",
        "geo_source_debt = GeoJSONDataSource(geojson=json.dumps(gdf_json_debt))\n",
        "geo_source_spendings = GeoJSONDataSource(geojson=json.dumps(gdf_json_spendings))\n",
        "\n",
        "# Define a linear color mapper for income values (using RdYlGn11 palette)\n",
        "spending_values = gdf_spendings['Difference_2023_2024']\n",
        "color_mapper_spending = LinearColorMapper(palette=RdYlGn11, low=spending_values.min(), high=spending_values.max())\n",
        "\n",
        "# Create a figure for incomes\n",
        "p_spending = figure(title=\"Puerto Rico Spending in 2024\",\n",
        "           height=350, width=1100,\n",
        "           tools=\"pan,wheel_zoom,box_zoom,reset,hover,save\",\n",
        "           tooltips=[(\"Town\", \"@ADM1_ES\"), (\"Spending\", \"@Difference_2023_2024\")])\n",
        "\n",
        "# Center the title\n",
        "p_spending.title.align = 'center'\n",
        "\n",
        "# Add patches for the geometries\n",
        "p_spending.patches('xs', 'ys', source=geo_source,\n",
        "          fill_color={'field': 'Difference_2023_2024', 'transform': color_mapper_spending},\n",
        "          line_color=\"black\", line_width=0.25, fill_alpha=0.7)\n",
        "\n",
        "# Add a color bar\n",
        "color_bar_spending = ColorBar(color_mapper=color_mapper_spending, location=(0, 0), orientation=\"horizontal\", title=\"Spending Value\")\n",
        "\n",
        "# Adjust the plot layout\n",
        "p_spending.add_layout(color_bar_spending, 'below')\n",
        "\n",
        "# Show the plot\n",
        "output_notebook()\n",
        "show(p_spending)\n"
      ],
      "metadata": {
        "id": "GOeVCyDwlyCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely import wkt\n",
        "from bokeh.io import output_notebook, show\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.models import HoverTool, GeoJSONDataSource, LinearColorMapper, ColorBar\n",
        "from bokeh.palettes import Viridis256\n",
        "import json\n",
        "\n",
        "# Enable output in Jupyter Notebook\n",
        "output_notebook()\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "data = pd.read_csv('merged_data_general_information.csv')\n",
        "\n",
        "# Replace spaces with underscores in column names\n",
        "data.columns = data.columns.str.replace(' ', '_')\n",
        "\n",
        "# Convert the 'geometry' column to valid geometry objects\n",
        "data['geometry'] = data['geometry'].apply(wkt.loads)\n",
        "\n",
        "# Convert the DataFrame to a GeoDataFrame\n",
        "merged_data_pr = gpd.GeoDataFrame(data, geometry='geometry')\n",
        "\n",
        "# Ensure 'Promedio_de_ingreso_familiar' is numeric\n",
        "merged_data_pr['Promedio_de_ingreso_familiar'] = pd.to_numeric(merged_data_pr['Promedio_de_ingreso_familiar'], errors='coerce')\n",
        "\n",
        "# Convert GeoDataFrame to GeoJSON\n",
        "merged_data_pr_json = json.loads(merged_data_pr.to_json())\n",
        "\n",
        "# Create a GeoJSONDataSource\n",
        "geo_source = GeoJSONDataSource(geojson=json.dumps(merged_data_pr_json))\n",
        "\n",
        "# Define a color mapper\n",
        "color_mapper = LinearColorMapper(palette=Viridis256, low=merged_data_pr['Promedio_de_ingreso_familiar'].min(), high=merged_data_pr['Promedio_de_ingreso_familiar'].max())\n",
        "\n",
        "# Create a figure\n",
        "p = figure(title='Average Family Income by Town',\n",
        "           height=360, width=1100, toolbar_location='below', tools='pan, wheel_zoom, box_zoom, reset')\n",
        "\n",
        "# Add patches to the figure\n",
        "p.patches('xs', 'ys', source=geo_source,\n",
        "          fill_color={'field': 'Promedio_de_ingreso_familiar', 'transform': color_mapper},\n",
        "          line_color='black', line_width=0.25, fill_alpha=1)\n",
        "\n",
        "# Add a hover tool\n",
        "hover = HoverTool()\n",
        "hover.tooltips = [(\"Municipio\", \"@ADM1_ES\"), (\"Promedio de Ingreso Familiar\", \"@Promedio_de_ingreso_familiar\")]\n",
        "p.add_tools(hover)\n",
        "\n",
        "# Add a color bar\n",
        "color_bar = ColorBar(color_mapper=color_mapper, label_standoff=8, width=500, height=20, location=(0,0), orientation='horizontal')\n",
        "p.add_layout(color_bar, 'below')\n",
        "\n",
        "# Show the plot\n",
        "show(p)\n"
      ],
      "metadata": {
        "id": "9itAhxiS3u3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "# URL of the zip file\n",
        "url = \"https://drive.google.com/uc?id=13551F3Ax4rIAVfNSfRr-MBJlQuXRqOnW&export=download\"\n",
        "\n",
        "# Your replacements dictionary\n",
        "replacements = {\n",
        "    'Mayagüez': 'Mayaguez',\n",
        "    'Canóvanas': 'Canovanas',\n",
        "    'Comerío': 'Comerio',\n",
        "    'Manatí': 'Manati',\n",
        "    'San Sebastián': 'San Sebastian',\n",
        "    'San Germán': 'San German',\n",
        "    'Rincón': 'Rincon',\n",
        "    'Juana Díaz': 'Juana Diaz',\n",
        "    'Loíza': 'Loiza',\n",
        "    'Bayamón': 'Bayamon',\n",
        "    'Río Grande': 'Rio Grande',\n",
        "    'Las Marías': 'Las Marias',\n",
        "    'Guánica': 'Guanica'\n",
        "}\n",
        "\n",
        "# Function to replace words in the column name based on replacements dictionary\n",
        "def replace_words(column_name, replacements):\n",
        "    for old_word, new_word in replacements.items():\n",
        "        if old_word in column_name:\n",
        "            column_name = column_name.replace(old_word, new_word)\n",
        "    return column_name\n",
        "\n",
        "# Download the zip file\n",
        "response = requests.get(url)\n",
        "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "\n",
        "# Extract the zip file\n",
        "zip_file.extractall(\"extracted_files\")\n",
        "\n",
        "# Get the list of CSV files in the extracted folder\n",
        "csv_files = [f for f in zip_file.namelist() if f.endswith('.csv')]\n",
        "\n",
        "# Create a new Excel writer object\n",
        "writer = pd.ExcelWriter(\"PR_Housing.xlsx\", engine='xlsxwriter')\n",
        "\n",
        "# Iterate through each CSV file\n",
        "for csv_file in csv_files:\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv(f\"extracted_files/{csv_file}\")\n",
        "    # Ensure all numeric columns are of type float\n",
        "    for column in df.columns:\n",
        "        try:\n",
        "            df[column] = pd.to_numeric(df[column])\n",
        "        except ValueError:\n",
        "            pass\n",
        "    # Get the first value under the column \"Geography\" for the sheet name\n",
        "    sheet_name = df['Geography'].iloc[0]\n",
        "    # Replace words in the sheet name based on the replacements dictionary\n",
        "    sheet_name = replace_words(sheet_name, replacements)\n",
        "    # Write the DataFrame to a sheet in the Excel file\n",
        "    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "# Save the Excel file\n",
        "writer.close()\n"
      ],
      "metadata": {
        "id": "ds4DMzpuOcos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "from shapely import wkt\n",
        "from bokeh.io import output_notebook, show\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.models import HoverTool, GeoJSONDataSource, LinearColorMapper, ColorBar\n",
        "from bokeh.palettes import Viridis256\n",
        "from bokeh.transform import linear_cmap\n",
        "import json\n",
        "\n",
        "# Load the Excel file\n",
        "excel_file = pd.ExcelFile(\"PR_Housing.xlsx\")\n",
        "\n",
        "# Load the sheet \"Puerto Rico\" into a DataFrame\n",
        "df = pd.read_excel(excel_file, sheet_name=\"Puerto Rico\")\n",
        "\n",
        "# Filter the DataFrame for the years 2022 and 2017\n",
        "df_2022 = df[df[\"Year\"] == 2022]\n",
        "df_2017 = df[df[\"Year\"] == 2017]\n",
        "\n",
        "# Find the index of the row where the \"Variable\" column indicates \"$1,000,000 or more\"\n",
        "index_limit_2022 = df_2022[df_2022[\"Variable\"] == \"$1,000,000 or more\"].index[0]\n",
        "index_limit_2017 = df_2017[df_2017[\"Variable\"] == \"$1,000,000 or more\"].index[0]\n",
        "\n",
        "# Filter the DataFrame up to this index\n",
        "df_filtered_2022 = df_2022.loc[:index_limit_2022]\n",
        "df_filtered_2017 = df_2017.loc[:index_limit_2017]\n",
        "\n",
        "# Extract data for the graphs\n",
        "x_values_2022 = df_filtered_2022[\"Variable\"]\n",
        "y_values_2022 = df_filtered_2022[\"Value\"]\n",
        "\n",
        "x_values_2017 = df_filtered_2017[\"Variable\"]\n",
        "y_values_2017 = df_filtered_2017[\"Value\"]\n",
        "\n",
        "# Extract the median values\n",
        "median_value_2022 = df_2022[df_2022[\"Variable\"] == \"Median Value (dollars)\"][\"Value\"].values[0]\n",
        "median_value_2017 = df_2017[df_2017[\"Variable\"] == \"Median Value (dollars)\"][\"Value\"].values[0]\n",
        "\n",
        "# Create the figure and axes for the side-by-side graphs\n",
        "fig, (ax2, ax1) = plt.subplots(1, 2, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "\n",
        "# Enhance the aesthetics of the plots\n",
        "def create_bar_plot(ax, x_values, y_values, title, color, median_value):\n",
        "    ax.bar(x_values, y_values, color=color, edgecolor='black', linewidth=0.8)\n",
        "    ax.set_xlabel(\"Property Values\", fontsize=12, labelpad=10)\n",
        "    ax.set_ylabel(\"Value\", fontsize=12, labelpad=10)\n",
        "    ax.set_ylim(0, 305000)\n",
        "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "    ax.set_xticklabels(x_values, rotation=45, ha='right', fontsize=10)\n",
        "    ax.grid(axis='y', linestyle='--', linewidth=0.7, alpha=0.7)\n",
        "    ax.text(0.95, 0.95, f\"Median Value: {median_value}\", ha='right', va='top', fontsize=12, fontweight='bold', transform=ax.transAxes, bbox=dict(facecolor='white', alpha=0.7))\n",
        "    for i, value in enumerate(y_values):\n",
        "        ax.text(i, value + 5000, str(value), ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Plot the graph for the year 2017\n",
        "create_bar_plot(ax2, x_values_2017, y_values_2017, \"Housing Values in 2017\", 'salmon', median_value_2017)\n",
        "\n",
        "# Plot the graph for the year 2022\n",
        "create_bar_plot(ax1, x_values_2022, y_values_2022, \"Housing Values in 2022\", 'skyblue', median_value_2022)\n",
        "\n",
        "plt.tight_layout(pad=3)  # Adjust the layout for better fit\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Load the shapefile\n",
        "prC2 = gpd.read_file('merged_shapefile.shp')\n",
        "\n",
        "# Load the Excel file\n",
        "excel_file = pd.ExcelFile(\"PR_Housing.xlsx\")\n",
        "\n",
        "# Create a list to store median values, geometries, and town names\n",
        "median_values = []\n",
        "geometries = []\n",
        "town_names = []\n",
        "\n",
        "# Collecting values without printing each match\n",
        "for sheet_name in excel_file.sheet_names:\n",
        "    if sheet_name in prC2[\"ADM1_ES\"].values:\n",
        "        # Load the sheet into a DataFrame\n",
        "        df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
        "\n",
        "        # Filter the DataFrame for median type data and year\n",
        "        median_data = df[(df[\"Type of Data\"].str.contains(\"median\", case=False, na=False)) & (df[\"Year\"] == 2022)]\n",
        "\n",
        "        # Extract the geometry and value\n",
        "        geometry = prC2[prC2[\"ADM1_ES\"] == sheet_name][\"geometry\"].values[0]\n",
        "        value = median_data[\"Value\"].mean()  # Taking the mean value if there are multiple entries\n",
        "\n",
        "        geometries.append(geometry)\n",
        "        median_values.append(value)\n",
        "        town_names.append(sheet_name)\n",
        "\n",
        "# Create a GeoDataFrame with the collected data\n",
        "geo_df = gpd.GeoDataFrame({'geometry': geometries, 'median_value': median_values, 'town': town_names}, crs=\"EPSG:4326\")\n",
        "\n",
        "# Convert GeoDataFrame to GeoJSON\n",
        "geo_json = json.loads(geo_df.to_json())\n",
        "\n",
        "# Create a GeoJSONDataSource\n",
        "geosource = GeoJSONDataSource(geojson=json.dumps(geo_json))\n",
        "\n",
        "# Define a linear color mapper\n",
        "color_mapper = LinearColorMapper(palette=Viridis256, low=min(median_values), high=max(median_values))\n",
        "\n",
        "# Create a figure\n",
        "p = figure(title=\"Housing in Puerto Rico by Median Values\", height=360, width=1100, tools=\"pan,wheel_zoom,box_zoom,reset,hover,save\")\n",
        "\n",
        "# Add patches to the figure\n",
        "p.patches('xs', 'ys', source=geosource,\n",
        "          fill_color={'field': 'median_value', 'transform': color_mapper},\n",
        "          line_color='black', line_width=0.25, fill_alpha=1)\n",
        "\n",
        "# Add hover tool\n",
        "hover = p.select_one(HoverTool)\n",
        "hover.point_policy = \"follow_mouse\"\n",
        "hover.tooltips = [(\"Town\", \"@town\"), (\"Median Housing Value $\", \"@median_value\")]\n",
        "\n",
        "# Add a color bar\n",
        "color_bar = ColorBar(color_mapper=color_mapper, location=(0, 0), orientation=\"horizontal\", title=\"Median Values\")\n",
        "\n",
        "# Adjust the plot layout\n",
        "p.add_layout(color_bar, 'below')\n",
        "\n",
        "# Show the plot\n",
        "output_notebook()\n",
        "show(p)"
      ],
      "metadata": {
        "id": "YcqcrZ_wGPAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely import wkt\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import json\n",
        "import folium\n",
        "\n",
        "# Load the merged data\n",
        "merged_with_incomes = pd.read_csv('merged_with_incomes.csv')\n",
        "merged_data_debt = pd.read_csv('merged_with_debts.csv')\n",
        "merged_data_spendings = pd.read_csv('merged_with_spendings.csv')\n",
        "\n",
        "# Convert the DataFrame to a GeoDataFrame\n",
        "merged_with_incomes['geometry'] = merged_with_incomes['geometry'].apply(wkt.loads)\n",
        "merged_data_debt['geometry'] = merged_data_debt['geometry'].apply(wkt.loads)\n",
        "merged_data_spendings['geometry'] = merged_data_spendings['geometry'].apply(wkt.loads)\n",
        "gdf_debt = gpd.GeoDataFrame(merged_data_debt, geometry='geometry')\n",
        "gdf_spendings = gpd.GeoDataFrame(merged_data_spendings, geometry='geometry')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Increase the maximum number of columns displayed\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n"
      ],
      "metadata": {
        "id": "Mb6jLRv6NgKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import Normalize\n",
        "from matplotlib.cm import ScalarMappable\n",
        "\n",
        "# Load the shapefile\n",
        "prC2 = gpd.read_file('merged_shapefile.shp')\n",
        "\n",
        "# Re-project geometries to a projected CRS\n",
        "prC2 = prC2.to_crs(epsg=3857)\n",
        "\n",
        "# Plot the map of Puerto Rico\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "prC2.boundary.plot(ax=ax, linewidth=1)\n",
        "prC2.plot(ax=ax, color='white', edgecolor='black')\n",
        "\n",
        "# Plot only Guanica's name\n",
        "guanica = prC2[prC2['ADM1_ES'].str.contains('Guanica', case=False, na=False)]\n",
        "for x, y, label in zip(guanica.geometry.centroid.x, guanica.geometry.centroid.y, guanica['ADM1_ES']):\n",
        "    ax.text(x, y, label, fontsize=8, ha='center', color='black')\n",
        "\n",
        "# Read the earthquake data\n",
        "earthquake_data = pd.read_csv('https://drive.google.com/uc?id=1eEI_6eKFouVUDKCcIr5-B6fQSyxGwZ40&export=download')\n",
        "\n",
        "# Convert earthquake data to GeoDataFrame and re-project\n",
        "earthquake_gdf = gpd.GeoDataFrame(earthquake_data, geometry=gpd.points_from_xy(earthquake_data.longitude, earthquake_data.latitude))\n",
        "earthquake_gdf = earthquake_gdf.set_crs(epsg=4326).to_crs(epsg=3857)\n",
        "\n",
        "# Find the earthquake with the highest magnitude\n",
        "highest_mag_earthquake = earthquake_gdf.loc[earthquake_gdf['mag'].idxmax()]\n",
        "\n",
        "# Normalize magnitudes for colormap\n",
        "norm = Normalize(vmin=earthquake_gdf['mag'].min(), vmax=earthquake_gdf['mag'].max())\n",
        "cmap = plt.get_cmap('YlOrRd')\n",
        "\n",
        "# Plot earthquakes with magnitudes 4 and below\n",
        "below_4 = earthquake_gdf[earthquake_gdf['mag'] <= 4]\n",
        "ax.scatter(\n",
        "    below_4.geometry.x, below_4.geometry.y,\n",
        "    s=below_4['mag'] * 4,  # Further decrease size for magnitudes 4 and below\n",
        "    c=below_4['mag'], cmap=cmap, norm=norm,\n",
        "    alpha=0.6, edgecolor='w', linewidth=0.5\n",
        ")\n",
        "\n",
        "# Plot earthquakes with magnitudes above 4\n",
        "above_4 = earthquake_gdf[earthquake_gdf['mag'] > 4]\n",
        "ax.scatter(\n",
        "    above_4.geometry.x, above_4.geometry.y,\n",
        "    s=above_4['mag'] ** 2 * 8,  # Reduce size for magnitudes above 4\n",
        "    c=above_4['mag'], cmap=cmap, norm=norm,\n",
        "    alpha=0.6, edgecolor='w', linewidth=0.5\n",
        ")\n",
        "\n",
        "# Highlight the earthquake with the highest magnitude\n",
        "ax.scatter(\n",
        "    highest_mag_earthquake.geometry.x, highest_mag_earthquake.geometry.y,\n",
        "    s=highest_mag_earthquake['mag'] ** 2 * 12,  # Increase size for emphasis\n",
        "    c='red', edgecolor='black', linewidth=1.5, label=f\"Highest Magnitude: {highest_mag_earthquake['mag']} (ID: {highest_mag_earthquake['id']})\"\n",
        ")\n",
        "\n",
        "# Plot the magnitude number on top of the highest magnitude circle\n",
        "ax.text(\n",
        "    highest_mag_earthquake.geometry.x, highest_mag_earthquake.geometry.y,\n",
        "    f\"{highest_mag_earthquake['mag']}\", ha='center', va='bottom', fontsize=12, fontweight='bold', color='red'\n",
        ")\n",
        "\n",
        "# Calculate and display the total number of earthquakes since 2020\n",
        "total_earthquakes = len(earthquake_gdf)\n",
        "ax.text(0.05, 0.95, f\"Earthquakes Since 2020: {total_earthquakes}\", ha='left', va='top', fontsize=7, fontweight='bold', transform=ax.transAxes, bbox=dict(facecolor='white', alpha=0.7))\n",
        "\n",
        "# Create a colorbar for magnitudes and place it below the plot\n",
        "sm = ScalarMappable(cmap=cmap, norm=norm)\n",
        "sm.set_array([])\n",
        "cbar = plt.colorbar(sm, ax=ax, orientation='horizontal', pad=0.15, aspect=50)\n",
        "cbar.set_label('Magnitude')\n",
        "\n",
        "plt.title('Earthquakes in Puerto Rico (Since 2020)')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ePfYjx2d6TyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The 2020 Puerto Rico earthquakes caused significant damage to many structures in the southwestern region of the island, including buildings, roadways, and bridges:\n",
        "•\tHomes: Over 8,000 homes were damaged, with about 2,500 uninhabitable.\n",
        "•\tSchools: The Escuela Intermedia Agripina Seda middle school in Guanica suffered major damage, including a partially collapsed, three-story building.\n",
        "•\tChurches: The Guyanilla Catholic Church in downtown Guyanilla was partially collapsed.\n",
        "•\tGovernment structures: Damage to government structures was calculated in the hundreds of millions.\n",
        "•\tOther structures: At least 80 structures collapsed completely.\n",
        "The earthquakes occurred in a series of events, starting on December 28, 2019 and continuing through January 2020. The first major event was a magnitude 5.8 earthquake on January 6, followed by a magnitude 6.4 earthquake on January 7, and a magnitude 5.6 earthquake on January 7. The region continued to experience aftershocks for years to decades.\n",
        "\n",
        "Thissrticle summarizes the events and presents many photos of damagedstructures in the southwest of the island: https://www.usatoday.com/picture-gallery/news/nation/2020/01/07/puerto-rico-earthquakes-cause-heavy-damage-and-knock-out-power/2830812001/\n",
        "\n",
        "This is the source for the earthquakes data: https://earthquake.usgs.gov/earthquakes/search/\n",
        "* I filtered my search for the years 2020 to 2024 and over the entire geographical area of Puerto Rico\n"
      ],
      "metadata": {
        "id": "h34qTmwdWvLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely import wkt\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "import json\n",
        "import folium\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "# Load the Excel file and shapefile for housing data\n",
        "excel_file = pd.ExcelFile(\"PR_Housing.xlsx\")\n",
        "prC2 = gpd.read_file('merged_shapefile.shp')\n",
        "\n",
        "# Create a list to store median values, geometries, and town names\n",
        "median_values = []\n",
        "geometries = []\n",
        "town_names = []\n",
        "\n",
        "# Collecting values without printing each match\n",
        "for sheet_name in excel_file.sheet_names:\n",
        "    if sheet_name in prC2[\"ADM1_ES\"].values:\n",
        "        # Load the sheet into a DataFrame\n",
        "        df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
        "\n",
        "        # Filter the DataFrame for median type data and year\n",
        "        median_data = df[(df[\"Type of Data\"].str.contains(\"median\", case=False, na=False)) & (df[\"Year\"] == 2022)]\n",
        "\n",
        "        # Extract the geometry and value\n",
        "        geometry = prC2[prC2[\"ADM1_ES\"] == sheet_name][\"geometry\"].values[0]\n",
        "        value = median_data[\"Value\"].mean()  # Taking the mean value if there are multiple entries\n",
        "\n",
        "        geometries.append(geometry)\n",
        "        median_values.append(value)\n",
        "        town_names.append(sheet_name)\n",
        "\n",
        "# Create a GeoDataFrame with the collected data\n",
        "geo_df = gpd.GeoDataFrame({'geometry': geometries, 'median_value': median_values, 'town': town_names}, crs=\"EPSG:4326\")\n",
        "\n",
        "# Function to create the population density map\n",
        "def create_population_density_map():\n",
        "    fig, ax = plt.subplots(1, figsize=(15, 25))\n",
        "    merged_data.plot(ax=ax, column='2023', legend=True, cmap='YlOrRd', scheme='natural_breaks', k=5,\n",
        "                     edgecolor='grey', linewidth=.7,\n",
        "                     legend_kwds={\"fmt\": \"{:,.0f}\", 'loc': 'lower right', 'title': 'Legend: Population',\n",
        "                                  'title_fontsize': 'medium', 'fontsize': 'medium', 'markerscale': 1.2})\n",
        "\n",
        "    # Set title and labels\n",
        "    ax.set_title('Population by Administrative Town', fontsize=15, pad=20, loc='left')\n",
        "    ax.set_xlabel('Longitude')\n",
        "    ax.set_ylabel('Latitude')\n",
        "\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "# Create Plotly figures\n",
        "fig_debt = px.choropleth(gdf_debt,\n",
        "                         geojson=gdf_debt.geometry,\n",
        "                         locations=gdf_debt.index,\n",
        "                         color=\"2024.0\",\n",
        "                         hover_name=\"ADM1_ES\",\n",
        "                         color_continuous_scale=[\"green\", \"lightgreen\", \"yellow\", \"orange\", \"red\"])\n",
        "fig_debt.update_geos(fitbounds=\"locations\", visible=False)\n",
        "fig_debt.update_layout(\n",
        "    margin={\"r\": 0, \"t\": 10, \"l\": 0, \"b\": 0},\n",
        "    width=1100, height=400,\n",
        "    coloraxis_colorbar=dict(\n",
        "        orientation='v', x=1.05, y=0.5, len=0.9, thickness=15,\n",
        "        title=\"Debt in Millions of Dollars\",\n",
        "        tickprefix=\"$\", ticksuffix=\"M\"\n",
        "    ),\n",
        "    annotations=[dict(\n",
        "        x=0.01,\n",
        "        y=0.99,\n",
        "        xref='paper',\n",
        "        yref='paper',\n",
        "        text=\"Debt for Administrative Towns in Puerto Rico         ~$37 Billions in 2023\",\n",
        "        showarrow=False,\n",
        "        xanchor='left',\n",
        "        yanchor='top',\n",
        "        font=dict(size=18)\n",
        "    )]\n",
        ")\n",
        "\n",
        "fig_spending = px.choropleth(gdf_spendings,\n",
        "                             geojson=gdf_spendings.geometry,\n",
        "                             locations=gdf_spendings.index,\n",
        "                             color=\"Difference_2023_2024\",\n",
        "                             hover_name=\"ADM1_ES\",\n",
        "                             color_continuous_scale=[\"green\", \"lightgreen\", \"yellow\", \"orange\", \"red\"])\n",
        "fig_spending.update_geos(fitbounds=\"locations\", visible=False)\n",
        "fig_spending.update_layout(\n",
        "    margin={\"r\": 0, \"t\": 10, \"l\": 0, \"b\": 0},\n",
        "    width=1100, height=400,\n",
        "    coloraxis_colorbar=dict(\n",
        "        orientation='v', x=1.05, y=0.5, len=0.9, thickness=15,\n",
        "        title=\"2023 Spending in Millions of Dollars\",\n",
        "        tickprefix=\"$\"\n",
        "    ),\n",
        "    annotations=[dict(\n",
        "        x=0.01,\n",
        "        y=0.99,\n",
        "        xref='paper',\n",
        "        yref='paper',\n",
        "        text=\"Puerto Rico Spending in 2024\",\n",
        "        showarrow=False,\n",
        "        xanchor='left',\n",
        "        yanchor='top',\n",
        "        font=dict(size=18)\n",
        "    )]\n",
        ")\n",
        "\n",
        "# Create the housing figure using Plotly for consistency\n",
        "fig_housing = px.choropleth(geo_df,\n",
        "                            geojson=geo_df.geometry,\n",
        "                            locations=geo_df.index,\n",
        "                            color=\"median_value\",\n",
        "                            hover_name=\"town\",\n",
        "                            color_continuous_scale=[\"green\", \"lightgreen\", \"yellow\", \"orange\", \"red\"])\n",
        "fig_housing.update_geos(fitbounds=\"locations\", visible=False)\n",
        "fig_housing.update_layout(\n",
        "    margin={\"r\": 0, \"t\": 10, \"l\": 0, \"b\": 0},\n",
        "    width=1100, height=400,\n",
        "    coloraxis_colorbar=dict(\n",
        "        orientation='v', x=1.05, y=0.5, len=0.9, thickness=15,\n",
        "        title=\"Property Values in Thousands of Dollars\",\n",
        "        tickprefix=\"$\"\n",
        "    ),\n",
        "    annotations=[dict(\n",
        "        x=0.01,\n",
        "        y=0.99,\n",
        "        xref='paper',\n",
        "        yref='paper',\n",
        "        text=\"Housing in Puerto Rico by Median Values\",\n",
        "        showarrow=False,\n",
        "        xanchor='left',\n",
        "        yanchor='top',\n",
        "        font=dict(size=18)\n",
        "    )]\n",
        ")\n",
        "\n",
        "# Add the folium map\n",
        "# Load the merged data for folium\n",
        "merged_with_incomes = pd.read_csv('merged_with_debts.csv')\n",
        "merged_with_incomes['geometry'] = merged_with_incomes['geometry'].apply(wkt.loads)\n",
        "gdf = gpd.GeoDataFrame(merged_with_incomes, geometry='geometry')\n",
        "gdf.set_crs(epsg=4326, inplace=True)\n",
        "\n",
        "# Initialize the map centered around Puerto Rico\n",
        "m = folium.Map(location=[18.2208, -66.5901], zoom_start=7.5)\n",
        "\n",
        "# Add GeoJson to the map with popup data from 'ADM1_ES', 'Difference_2023_2024', 'Difference_Symbol'\n",
        "tooltip = folium.GeoJsonTooltip(fields=['ADM1_ES', 'Difference_2023_2024', 'Difference_Symbol'],\n",
        "                                aliases=['Town: ', 'Difference 2023-2024: ', 'Difference Symbol: '],\n",
        "                                localize=True)\n",
        "folium.GeoJson(gdf, tooltip=tooltip).add_to(m)\n",
        "\n",
        "# Convert the folium map to an HTML iframe\n",
        "from IPython.display import IFrame\n",
        "map_iframe = IFrame('map_with_geometry.html', width=1600, height=800)\n",
        "\n",
        "# Read the Excel file for population histograms\n",
        "df_pop_count = pd.read_excel(\"https://docs.google.com/uc?id=1F17rr2JNpUaFBIEgvsXMY2QFjiGAhyc5&export=download\")\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_pop_count.to_csv(\"pop_count.csv\", index=False)\n",
        "\n",
        "# Read the CSV file with float values\n",
        "df_population_count = pd.read_csv(\"pop_count.csv\")\n",
        "\n",
        "# Remove rows from index 86 and above as they contain extra information that we don't need\n",
        "df_population_count = df_population_count.iloc[:86]\n",
        "\n",
        "# Remove the decimal point and '+' sign in the 'Age' column if present\n",
        "df_population_count['Age'] = df_population_count['Age'].apply(lambda x: str(x).replace('.', '').replace('+', '') if '.' in str(x) or '+' in str(x) else str(x))\n",
        "\n",
        "# Ensure 'Age' column is numeric\n",
        "df_population_count['Age'] = pd.to_numeric(df_population_count['Age'])\n",
        "\n",
        "# Identify the correct column names for '2020 Total Population' and '2023 Total Population'\n",
        "column_name_2020 = [col for col in df_population_count.columns if '2020 Total' in col][0]\n",
        "column_name_2023 = [col for col in df_population_count.columns if '2023 Total' in col][0]\n",
        "\n",
        "# Get the population numbers for 85-year-olds in 2020 and 2023\n",
        "population_85_2020 = df_population_count.loc[df_population_count['Age'] == 85, column_name_2020].values[0]\n",
        "population_85_2023 = df_population_count.loc[df_population_count['Age'] == 85, column_name_2023].values[0]\n",
        "\n",
        "# Calculate the increase in numbers and percentage\n",
        "increase_85_population = population_85_2023 - population_85_2020\n",
        "increase_percentage = (increase_85_population / population_85_2020) * 100\n",
        "\n",
        "\n",
        "# Function to create the histogram figures (continued)\n",
        "def create_population_histograms():\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
        "\n",
        "    # 2020 Population Histogram\n",
        "    ax1.bar(df_population_count['Age'], df_population_count[column_name_2020], color='blue')\n",
        "    ax1.set_xlabel('Age')\n",
        "    ax1.set_ylabel('Total Population')\n",
        "    ax1.set_title('Age vs 2020 Total Population', fontsize=15, pad=20)\n",
        "    ax1.set_ylim(0, 130000)  # Increase the y-axis limit\n",
        "    ax1.grid(axis='y', linestyle='--', linewidth=0.7)\n",
        "    ax1.annotate(f'85: {population_85_2020}', xy=(85, population_85_2020), xytext=(75, population_85_2020 + 5000),\n",
        "                 arrowprops=dict(arrowstyle='-', color='blue'), fontsize=10, ha='center', color='blue')\n",
        "\n",
        "    # 2023 Population Histogram\n",
        "    ax2.bar(df_population_count['Age'], df_population_count[column_name_2023], color='green')\n",
        "    ax2.set_xlabel('Age')\n",
        "    ax2.set_title('Age vs 2023 Total Population', fontsize=15, pad=20)\n",
        "    ax2.set_ylim(0, 130000)  # Increase the y-axis limit\n",
        "    ax2.grid(axis='y', linestyle='--', linewidth=0.7)\n",
        "    ax2.annotate(f'85: {population_85_2023}', xy=(85, population_85_2023), xytext=(75, population_85_2023 + 5000),\n",
        "                 arrowprops=dict(arrowstyle='-', color='green'), fontsize=10, ha='center', color='green')\n",
        "\n",
        "    # Highlight the increase in numbers and percentage\n",
        "    ax2.annotate(f'Increase: {increase_85_population}\\n({increase_percentage:.2f}%)', xy=(85, population_85_2023 / 2),\n",
        "                 xytext=(70, population_85_2023 / 2 + 15000),\n",
        "                 arrowprops=dict(arrowstyle='-', color='red'), fontsize=10, ha='center', color='red')\n",
        "\n",
        "    # Show the plots side by side\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "# Function to load data for a specific town\n",
        "def load_town_data(sheet_name):\n",
        "    df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
        "\n",
        "    # Filter the DataFrame for the years 2022 and 2017\n",
        "    df_2022 = df[df[\"Year\"] == 2022]\n",
        "    df_2017 = df[df[\"Year\"] == 2017]\n",
        "\n",
        "    # Find the index of the row where the \"Variable\" column indicates \"$1,000,000 or more\"\n",
        "    index_limit_2022 = df_2022[df_2022[\"Variable\"] == \"$1,000,000 or more\"].index[0]\n",
        "    index_limit_2017 = df_2017[df_2017[\"Variable\"] == \"$1,000,000 or more\"].index[0]\n",
        "\n",
        "    # Filter the DataFrame up to this index\n",
        "    df_filtered_2022 = df_2022.loc[:index_limit_2022]\n",
        "    df_filtered_2017 = df_2017.loc[:index_limit_2017]\n",
        "\n",
        "    return df_filtered_2017, df_filtered_2022\n",
        "\n",
        "# Function to create bar plots for a given DataFrame and axis\n",
        "def create_bar_plot(ax, x_values, y_values, title, color):\n",
        "    ax.bar(x_values, y_values, color=color, edgecolor='black', linewidth=0.8)\n",
        "    ax.set_xlabel(\"Property Values\", fontsize=12, labelpad=10)\n",
        "    ax.set_ylabel(\"Value\", fontsize=12, labelpad=10)\n",
        "    max_value = max(y_values)\n",
        "    ax.set_ylim(0, max_value * 1.1)  # Set Y-axis limit based on max value with some padding\n",
        "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        ax.set_xticklabels(x_values, rotation=45, ha='right', fontsize=10)\n",
        "    ax.grid(axis='y', linestyle='--', linewidth=0.7, alpha=0.7)\n",
        "    for i, value in enumerate(y_values):\n",
        "        ax.text(i, value + max_value * 0.02, str(value), ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Create a dropdown menu for selecting towns\n",
        "towns_dropdown = widgets.Dropdown(\n",
        "    options=excel_file.sheet_names,\n",
        "    value='Puerto Rico',\n",
        "    description='Select Town:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "# Output widget to display the graphs\n",
        "output_housing_value = widgets.Output()\n",
        "\n",
        "# Function to update graphs based on selected town\n",
        "def update_graphs(change):\n",
        "    sheet_name = change['new']\n",
        "    df_filtered_2017, df_filtered_2022 = load_town_data(sheet_name)\n",
        "\n",
        "    x_values_2017 = df_filtered_2017[\"Variable\"]\n",
        "    y_values_2017 = df_filtered_2017[\"Value\"]\n",
        "    x_values_2022 = df_filtered_2022[\"Variable\"]\n",
        "    y_values_2022 = df_filtered_2022[\"Value\"]\n",
        "\n",
        "    with output_housing_value:\n",
        "        output_housing\n",
        "\n",
        "# Function to update graphs based on selected town\n",
        "def update_graphs(change):\n",
        "    sheet_name = change['new']\n",
        "    df_filtered_2017, df_filtered_2022 = load_town_data(sheet_name)\n",
        "\n",
        "    x_values_2017 = df_filtered_2017[\"Variable\"]\n",
        "    y_values_2017 = df_filtered_2017[\"Value\"]\n",
        "    x_values_2022 = df_filtered_2022[\"Variable\"]\n",
        "    y_values_2022 = df_filtered_2022[\"Value\"]\n",
        "\n",
        "    with output_housing_value:\n",
        "        output_housing_value.clear_output()\n",
        "        fig, (ax2, ax1) = plt.subplots(1, 2, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "        create_bar_plot(ax2, x_values_2017, y_values_2017, f\"{sheet_name} Housing Median Values in 2017\", 'salmon')\n",
        "        create_bar_plot(ax1, x_values_2022, y_values_2022, f\"{sheet_name} Housing Median Values in 2022\", 'skyblue')\n",
        "        plt.tight_layout(pad=3)\n",
        "        plt.show()\n",
        "\n",
        "# Attach the update function to the dropdown menu\n",
        "towns_dropdown.observe(update_graphs, names='value')\n",
        "\n",
        "# Display the initial graphs for \"Puerto Rico\"\n",
        "df_filtered_2017, df_filtered_2022 = load_town_data(\"Puerto Rico\")\n",
        "x_values_2017 = df_filtered_2017[\"Variable\"]\n",
        "y_values_2017 = df_filtered_2017[\"Value\"]\n",
        "x_values_2022 = df_filtered_2022[\"Variable\"]\n",
        "y_values_2022 = df_filtered_2022[\"Value\"]\n",
        "\n",
        "# Display the initial graphs\n",
        "with output_housing_value:\n",
        "    fig, (ax2, ax1) = plt.subplots(1, 2, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "    create_bar_plot(ax2, x_values_2017, y_values_2017, \"Puerto Rico Housing Median Values in 2017\", 'salmon')\n",
        "    create_bar_plot(ax1, x_values_2022, y_values_2022, \"Puerto Rico Housing Median Values in 2022\", 'skyblue')\n",
        "    plt.tight_layout(pad=3)\n",
        "    plt.show()\n",
        "\n",
        "# Create button widgets\n",
        "button_population_density = widgets.Button(description=\"PopulationMap\", button_style='success')\n",
        "button_histograms = widgets.Button(description=\"PopulationHistogram\", button_style='')\n",
        "button_debt = widgets.Button(description=\"Debt Map\", button_style='')\n",
        "button_spending = widgets.Button(description=\"Spending Map\", button_style='')\n",
        "button_housing = widgets.Button(description=\"Housing Map\", button_style='')\n",
        "button_housing_value = widgets.Button(description=\"Housing Value\", button_style='')\n",
        "button_map = widgets.Button(description=\"Geographic Map\", button_style='')\n",
        "\n",
        "# Output widget to display the map and other figures\n",
        "output = widgets.Output()\n",
        "\n",
        "# Callback functions for the buttons\n",
        "def on_button_population_density_clicked(b):\n",
        "    output.clear_output(wait=True)\n",
        "    with output:\n",
        "        fig_population_density = create_population_density_map()\n",
        "        display(fig_population_density)\n",
        "    button_population_density.button_style = 'success'\n",
        "    button_histograms.button_style = ''\n",
        "    button_debt.button_style = ''\n",
        "    button_spending.button_style = ''\n",
        "    button_housing.button_style = ''\n",
        "    button_housing_value.button_style = ''\n",
        "    button_map.button_style = ''\n",
        "\n",
        "def on_button_histograms_clicked(b):\n",
        "    output.clear_output(wait=True)\n",
        "    with output:\n",
        "        fig_histograms = create_population_histograms()\n",
        "        display(fig_histograms)\n",
        "    button_population_density.button_style = ''\n",
        "    button_histograms.button_style = 'success'\n",
        "    button_debt.button_style = ''\n",
        "    button_spending.button_style = ''\n",
        "    button_housing.button_style = ''\n",
        "    button_housing_value.button_style = ''\n",
        "    button_map.button_style = ''\n",
        "\n",
        "def on_button_debt_clicked(b):\n",
        "    output.clear_output(wait=True)\n",
        "    with output:\n",
        "        display(fig_debt)\n",
        "    button_population_density.button_style = ''\n",
        "    button_histograms.button_style = ''\n",
        "    button_debt.button_style = 'success'\n",
        "    button_spending.button_style = ''\n",
        "    button_housing.button_style = ''\n",
        "    button_housing_value.button_style = ''\n",
        "    button_map.button_style = ''\n",
        "\n",
        "def on_button_spending_clicked(b):\n",
        "    output.clear_output(wait=True)\n",
        "    with output:\n",
        "        display(fig_spending)\n",
        "    button_population_density.button_style = ''\n",
        "    button_histograms.button_style = ''\n",
        "    button_debt.button_style = ''\n",
        "    button_spending.button_style = 'success'\n",
        "    button_housing.button_style = ''\n",
        "    button_housing_value.button_style = ''\n",
        "    button_map.button_style = ''\n",
        "\n",
        "def on_button_housing_clicked(b):\n",
        "    output.clear_output(wait=True)\n",
        "    with output:\n",
        "        display(fig_housing)\n",
        "    button_population_density.button_style = ''\n",
        "    button_histograms.button_style = ''\n",
        "    button_debt.button_style = ''\n",
        "    button_spending.button_style = ''\n",
        "    button_housing.button_style = 'success'\n",
        "    button_housing_value.button_style = ''\n",
        "    button_map.button_style = ''\n",
        "\n",
        "def on_button_housing_value_clicked(b):\n",
        "    output.clear_output(wait=True)\n",
        "    with output:\n",
        "        display(widgets.VBox([\n",
        "            widgets.HTML(\"<h2 style='text-align:center;'>Select Town:</h2>\"),\n",
        "            towns_dropdown,\n",
        "            output_housing_value\n",
        "        ], layout=widgets.Layout(justify_content='center', align_items='center', margin='0')))\n",
        "    button_population_density.button_style = ''\n",
        "    button_histograms.button_style = ''\n",
        "    button_debt.button_style = ''\n",
        "    button_spending.button_style = ''\n",
        "    button_housing.button_style = ''\n",
        "    button_housing_value.button_style = 'success'\n",
        "    button_map.button_style = ''\n",
        "\n",
        "def on_button_map_clicked(b):\n",
        "    output.clear_output(wait=True)\n",
        "    with output:\n",
        "        display(m)\n",
        "    button_population_density.button_style = ''\n",
        "    button_histograms.button_style = ''\n",
        "    button_debt.button_style = ''\n",
        "    button_spending.button_style = ''\n",
        "    button_housing.button_style = ''\n",
        "    button_housing_value.button_style = ''\n",
        "    button_map.button_style = 'success'\n",
        "\n",
        "button_population_density.on_click(on_button_population_density_clicked)\n",
        "button_histograms.on_click(on_button_histograms_clicked)\n",
        "button_debt.on_click(on_button_debt_clicked)\n",
        "button_spending.on_click(on_button_spending_clicked)\n",
        "button_housing.on_click(on_button_housing_clicked)\n",
        "button_housing_value.on_click(on_button_housing_value_clicked)\n",
        "button_map.on_click(on_button_map_clicked)\n",
        "\n",
        "# Display the updated dashboard\n",
        "display(widgets.HTML(\"<h1 style='text-align:center; margin-bottom:10px;'>Puerto Rico GIS Project</h1>\"))\n",
        "display(widgets.VBox([\n",
        "    widgets.HBox([button_population_density, button_histograms, button_debt, button_spending, button_housing, button_housing_value, button_map], layout=widgets.Layout(justify_content='center', margin='0 0 5px 0')),\n",
        "    output\n",
        "], layout=widgets.Layout(justify_content='center', align_items='center', margin='0')))\n",
        "\n",
        "# Initial display of Population Density Map\n",
        "output.clear_output(wait=True)\n",
        "with output:\n",
        "    fig_population_density = create_population_density_map()\n",
        "    display(fig_population_density)\n",
        "\n",
        "# Button style initialization\n",
        "button_population_density.button_style = 'success'\n",
        "button_histograms.button_style = ''\n",
        "button_debt.button_style = ''\n",
        "button_spending.button_style = ''\n",
        "button_housing.button_style = ''\n",
        "button_housing_value.button_style = ''\n",
        "button_map.button_style = ''\n"
      ],
      "metadata": {
        "id": "sXkP45OVrH2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Population Changes Explanation:** Over the past ten years, Puerto Rico has seen an exodus of over 300,000 residents. The causes are manifold: government mismanagement paired with relentless natural disasters has compelled many to leave. This mass departure has further weakened economic activities, strained educational institutions, and left fewer taxpayers to bear the financial burden. Recent data and analyses indicate that the outmigration continued strongly in 2023, with the devastating effects of Hurricanes Irma and Maria significantly exacerbating this trend.\n",
        "\n",
        "Resource: https://wioaplans.ed.gov/node/13521#:~:text=In%20the%20past%20decade%20more,16%25%20decline%20expected%20by%20FY22.\n",
        "\n",
        "\n",
        "**Histograms Explanation:** The histograms above shows there was a ~20% increase in population older than 65 years in Puerto Rico. This aligns with a study conducted by Oxford and titled: Aging and the Left Behind: Puerto Rico and Its Unconventional Rapid Aging (https://academic.oup.com/gerontologist/article/62/7/964/6607773) that highlights something really interesting \"Puerto Rico is aging more rapidly than almost any country\".\n",
        "\n",
        "\n",
        "**Debt Map Explanation:** As of 2023, Puerto Rico's total debt stands at approximately 37 billion after a significant restructuring process, which reduced its previous debt of over 70 billion through the oversight board established under PROMESA; this represents a roughly 80% reduction in total liabilities.\n",
        "Resource: https://oversightboard.pr.gov/debt/#:~:text=The%20Oversight%20Board%2C%20together%20with,claims%2C;%20but%20excludes%20CVI%20Claims\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ius7xDKtQ6nu"
      }
    }
  ]
}